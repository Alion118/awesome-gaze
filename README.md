# Awesome Gaze
A curated list of awesome gaze estimation papers, codes, datasets and other awesomeness.

## Table of Content

* [Review Papers](#Review-Papers)
* [Journal Papers](#Journal-Papers)
* [Conference Papers](#Conference-Papers)
* [arXiv Papers](#arXiv-papers)
* [Datasets](#Datasets)
* [Contribution](#Contribution)
* [License](#License)

## Review Papers

* Mohamed Khamis, Florian Alt, Andreas Bulling. **The Past, Present, and Future of Gaze-enabled Handheld Mobile Devices: Survey and Lessons Learned** [PDF](http://eprints.gla.ac.uk/170199/1/170199.pdf) [Code][MobileHCI2018 IEEE]

* Anuradha Kar and Peter Corcoran. **A Review and Analysis of Eye-Gaze Estimation Systems, Algorithms and Performance Evaluation Methods in Consumer Platforms** [PDF](https://ieeexplore.ieee.org/document/8003267) [Code] [Kar-Corcoran2017 IEEE]

* kshay A Gawande, Gangotri Nathaney. **A Survey on Gaze Estimation Techniques in Smartphone** [PDF](https://www.irjet.net/archives/V4/i4/IRJET-V4I4651.pdf) [Code] [Gawande-Nathaney2017 IRJET]

* Xiaomeng Wang, Kang Liu, Xu Qian. **A Survey on Gaze Estimation** [PDF](https://ieeexplore.ieee.org/document/7383057) [Code] [Wang-etal2015 ISKE]

* M. V. Sireesha, P. A. Vijaya, K. Chellamma. **A Survey on Gaze Estimation Techniques** [PDF](https://link.springer.com/chapter/10.1007%2F978-81-322-1524-0_43) [Code] [Sireesha-etal2013 LNEE]

* D.W. Hansen, Qiang Ji. **In the Eye of the Beholder: A Survey of Models for Eyes and Gaze** [PDF](https://ieeexplore.ieee.org/document/4770110) [Code] [Hansen-Ji2010 TPAMI]

* Abdallahi Ould, Mohamed Matthieu, Perreira Da Silva, Vincent Courboulay. **A history of eye gaze tracking** [PDF](https://hal.archives-ouvertes.fr/hal-00215967/document) [Code] [Ould-etal2008 HAL] 

* Carlos H. Morimoto, Marcio R.M. Mimica. **Eye gaze tracking techniques for interactive applications** [PDF](https://www.sciencedirect.com/science/article/pii/S1077314204001109) [Code] [Morimoto-Mimica2005 CVIU]

## Journal Papers

## Conference Papers

### CVPR 2019

* Yunyang Xiong, Hyunwoo J. Kim, Vikas Singh. **Mixed Effects Convolutional Neural Networks (MeNets) with Applications to Gaze Estimation** [PDF](http://openaccess.thecvf.com/content_CVPR_2019/papers/Xiong_Mixed_Effects_Neural_Networks_MeNets_With_Applications_to_Gaze_Estimation_CVPR_2019_paper.pdf) [Code]()

* Yu Yu, Gang Liu, Jean-Marc Odobez. **Improving User-Specific Gaze Estimation via Gaze Redirection Synthesis** [PDF](https://www.idiap.ch/~odobez/publications/YuLiuOdobez-CVPR2019.pdf) [Code]()

* Kang Wang, Hui Su, Qiang Ji. **Neuro-inspired Eye Tracking with Eye Movement Dynamics** [PDF](http://homepages.rpi.edu/~wangk10/papers/wang2019neural.pdf) [Code]()

* Kang Wang, Rui Zhao, Hui Su, Qiang Ji. **Generalizing Eye Tracking with Bayesian Adversarial Learning** [PDF](http://homepages.rpi.edu/~wangk10/papers/wang2019generalize.pdf) [Code]()

### CVPR 2018

* Brian Dolhansky, Cristian Canton Ferrer. **Eye In-Painting with Exemplar Generative Adversarial Networks** [PDF](https://arxiv.org/pdf/1712.03999.pdf) [Code](https://github.com/zhangqianhui/Exemplar-GAN-Eye-Inpainting-Tensorflow)

* Yanyu Xu, Yanbing Dong, Junru Wu, Zhengzhong Sun, Zhiru Shi, Jingyi Yu, Shenghua Gao. **Gaze Prediction in Dynamic 360Â° Immersive Videos** [PDF](http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Gaze_Prediction_in_CVPR_2018_paper.pdf) [Code](https://github.com/xuyanyu-shh/VR-EyeTracking)

* Kang Wang, Rui Zhao, Qiang Ji. **A Hierarchical Generative Model for Eye Image Synthesis and Eye Gaze Estimation** [PDF](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_A_Hierarchical_Generative_CVPR_2018_paper.pdf) [Code]()

* Arun Balajee Vasudevan, Dengxin Dai, Luc Van Gool. **Object Referring in Videos with Language and Human Gaze** [PDF](https://arxiv.org/pdf/1801.01582.pdf) [Code](https://github.com/arunbalajeev/gaze-interface)

* Fan, Lifeng and Chen, Yixin and Wei, Ping and Wang, Wenguan and Zhu, Song-Chun. **Inferring Shared Attention in Social Scene Videos** [PDF](http://www.stat.ucla.edu/~pwei/items/publications/Conf_2018_CVPR_SharedAttention.pdf) [Code]()

* Ping Wei, Yang Liu, Tianmin Shu, Nanning Zheng, Song-Chun Zhu. **Where and Why Are They Looking? Jointly Inferring Human Attention and Intentions in Complex Tasks** [PDF](http://www.stat.ucla.edu/~sczhu/papers/Conf_2018/CVPR_2018_Attention_Intention.pdf) [Code]()

* Rajeev Ranjan, Shalini De Mello, Jan Kautz. **Light-weight Head Pose Invariant Gaze Tracking** [PDF](https://arxiv.org/pdf/1804.08572.pdf) [Code]()

## arXiv Papers

## Datasets

|Dataset|RGB/RGB-D|Image type|Annotation type|Images|Distance|Head pose annot.|Gaze annot.|Head pose orient.|
|---|---|---|---|---|---|---|---|---|
|[MPII Gaze](https://github.com/trakaros/MPIIGaze)|RGB|Face + Eye Patches|Gaze Vector|213.659|40-60cm|Y|Y|Frontal|
	


## Reference

Many papers collections are from [Awesome-Gaze-Estimation](https://github.com/cvlab-uob/Awesome-Gaze-Estimation) by [Computer Vision Research Lab at the University of Birmingham](https://github.com/cvlab-uob)

## Contribution

If you have anything that you think they are awesome related to Gaze Estimation, feel free to send a [pull request](https://github.com/WuZhuoran/awesome-gaze/pulls)

## License

[![CC0](https://camo.githubusercontent.com/60561947585c982aee67ed3e3b25388184cc0aa3/687474703a2f2f6d6972726f72732e6372656174697665636f6d6d6f6e732e6f72672f70726573736b69742f627574746f6e732f38387833312f7376672f63632d7a65726f2e737667)](http://creativecommons.org/publicdomain/zero/1.0/)

To the extent possible under law, [Zhuoran Wu](https://github.com/WuZhuoran) has waived all copyright and related or neighboring rights to this work. If you want to use any items in this list, please refer their own License.